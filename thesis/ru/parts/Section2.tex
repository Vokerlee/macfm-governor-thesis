\section{Обзор существующих решений}
\label{sec:Section2} \index{Section2}

\subsection{Регулирование тактовых частот ЦП}

\subsubsection{Технология DVFS} \label{DVFS_Chapter}

    Почти все электронные схемы являются логическими элементами, которые имеют источник тактирования
    и работают на определённой частоте. Однако некоторым устройствам не выгодно работать при
    строго фиксированной частоте, например, если ядро процессора часто ждёт операции ввода-вывода,
    то эффективнее снизить тактовую частоту для более экономного расходования энергии, не сильно
    потеряв в производительности.

    Технология DVFS (Dynamic Voltage-Frequency Scaling) позволяет в режиме реального времени
    регулировать тактовую частоту и напряжение, с которыми работает устройство. Как правило,
    возможные значения тактовых частот являются дискретным набором, причём для каждой тактовой частоты
    существует минимальное значение напряжения, при котором устройство всё ещё остаётся в
    работоспособном состоянии.

    Практически все современные процессоры используют DVFS для регулировки тактовых частот ядер. В случае
    гетерогенных систем, т.е. имеющих кластеры ядер с различными характеристиками (например, более
    энергоэффективные или более производительные ядра), коими на сегодняшний день являются
    большинство мобильных компьютерных систем, предоставляется возможным регулировать тактовые частоты
    только целиком всего кластера, то есть всех ядер в кластере одновременно, а не каждого ядра по отдельности.

    Регулирование тактовых частот и напряжений используется не только в случае процессорных ядер, но также
    и в других компонентах компьютерных систем: ОЗУ, шины, кеши и т.д..

    Наибольший интерес в данной работе представляет алгоритм регулирования тактовых частот процессорных
    ядер, регулирование тактовых частот прочих компонент рассматриваться не будет.

\subsubsection{Политики регулирования частот в ядре Linux}

    Единственным способом регулирования тактовых частот ядер процессора в ядре Linux является
    использование драйвера $cpufreq$, который предоставляет несколько политик
    регулирования \cite{KernelCPUfreq}:
    \begin{enumerate}
        \item ''Performance'' -- тактовая частота ядра процессора выставляется в максимальное значение.
        \item ''Powersave'' -- тактовая частота ядра процессора выставляется в минимальное значение.
        \item ''Userspace'' -- тактовая частота ядра процессора выставляется пользователем.
        \item ''Ondemand'' -- тактовая частота ядра процессора выставляется в зависимости от доли времени
        использования ядра за фиксированный промежуток времени (далее обозначается как утилизации
        ядерного времени).
        \item ''Conservative'' -- поведение аналогично политике ''Ondemand'', но частота меняется менее
        резко, небольшими шагами.
        \item ''Schedutil'' \cite{KernelDocsSchedutil} -- поведение аналогично политике ''Ondemand'',
        но утилизация отслеживается не для ядер процессора, а для каждого потока исполнения;
        используется более продвинутая система подсчёта утилизации ядерного времени для потока исполнения:
        не только за фиксированный промежуток времени, а за несколько таких промежутков подряд с учётом
        весов каждого промежутка времени (более давние промежутки менее важны); в случае использования
        не CFS (Completely Fair Scheduler) планировщика, который является стандартным в Linux версии 6.1,
        а дедлайн планировщика (DL) или реального времени (RT), тактовая частота выставляется в
        максимальное значение.
    \end{enumerate}

    Политика ''Performance'' приводит к излишнему энергопотреблению, ''Powersave'' -- к потере
    производительности, ''Ondemand'' и ''Conservative'' -- не отслеживают утилизацию ядерного времени
    отдельно по потокам исполнения, к тому же не учитывают, что производительность ядра ЦП (которая
    обратно пропорциональна утилизации ядерного времени) может быть нелинейна относительно тактовой
    частоты (например, если процессор проводит основное время в ожидании выполнения транзакции-чтения
    из памяти), поэтому могут выставлять заведомо завышенное значения тактовой частоты, что приводит
    к дополнительному энергопотреблению, или медленно реагировать на повышение утилизации ядерного времени,
    что приводит к деградации производительности.

    ''Schedutil'' устраняет большинство недостатков политик регулирования частот, рассмотренных выше,
    но всё же он не учитывает возможную нелинейность производительности ЦП от тактовой частоты ядра
    процессора.

    Ещё один существенный недостаток всех политик, рассмотренных выше, является предположение,
    что частота любого ядра процессора может изменяться независимо от остальных.
    Как было упомянуто в \ref{DVFS_Chapter}, в современных мобильных системах ядра группируются
    в кластеры и частоты могут меняться только целиком для всего кластера.

\subsubsection{Подсчёт утилизации ядерного времени в Linux} \label{linux_util}

    В ядре Linux версии 6.1 в стандартном планировщике CFS (Completely Fair Scheduler)
    используется решение \cite{KernelDocsCapacity}, в котором при подсчёте утилизации ядерного времени
    приложением учитывается тот факт, что ядра различного типа (в разных кластерах) имеют разную
    производительность, и что в рамках одного ядра ЦП производительность меняется
    в зависимости от выбранной частоты.

    Однако авторы такого решения полностью пренебрегли тем фактом, что отношение максимальных
    производительностей двух различных ядер не является константой, а сильно зависит от
    исполняемой рабочей нагрузки (приложения). Также не учтено, что зависимость производительности,
    измеряемой в количестве исполненных инструкций в единицу времени, обычно нелинейна относительно
    тактовой частоты ядра процессора (так как скорость исполнения инструкций зависит не только от
    тактовой частоты ядра, но и характеристик компонент памяти).

    Таким образом, авторы вводят величину ёмкости производительности ядра процессора,
    измеряемой количеством исполненных инструкций в единицу времени при заданной тактовой частоте
    при условии максимальной утилизации ядерного времени. Величина утилизации вводится как часть
    ёмкости производительности, использованной при заданной утилизации ядерного времени (т.е.
    меньше утилизация ядерного времени -- меньше величина утилизации).

    Более формально, если за фиксированный интервал времени $\tau$ $i$-ое ядро процессора было задействовано
    время $\Delta t$, то утилизация ядерного времени равна $\Delta t / \tau$, а для
    $i$-ого ядра процессора формула утилизации имеет следующий вид:

    \begin{equation} \label{util_linux_formula}
        util = 1024 \cdot \frac{\Delta t}{\tau} \cdot \frac{freq_{cpu_{i}}}{freq^{max}_{cpu_{i}}} \cdot
               \frac{capacity_{cpu_{i}}}{\max_i \{capacity_{cpu_{i}} |_{freq_{cpu_i} = freq_{cpu_i}^{max}}\}} =
            inv_{i, freq},
    \end{equation}
    где $freq_{cpu_{i}}$ -- тактовая частота ядра процессора, при которой была измерена утилизация
    ядерного времени $\Delta t$, $freq^{max}_{cpu_{i}}$ -- максимально возможная тактовая частота ядра
    процессора, $capacity_{cpu_{i}}$ -- ёмкость производительности $i$-ого ядра при заданной
    тактовой частоте, $capacity_{cpu_{i}} |_{freq_{cpu_i} = freq_{cpu_i}^{max}}$ -- ёмкость этого
    же ядра при максимально возможной тактовой частоте. Коэффициент $1024$ введён для удобства.

    Ёмкости производительности вычисляются единожды с помощью измерений для конкретных сценариев
    исполнения (приложений) и применяются во всех остальных случаях без каких-либо обоснований,
    причём с линейной зависимостью производительности от тактовой частоты ядра, что неверно
    в большинстве случаев.

    В реальности используется утилизация, подсчитанная не за один промежутков времени, а сразу за
    несколько промежутков времени (обычно одинаковых по длительности), например, PELT
    (Per Entity Load Tracking) \cite{KernelDocsSchedutil} использует экспоненциально движущееся
    среднее значение утилизаций, подсчитанных по формулам выше.

    В качестве альтернативы PELT, который официально представлен в ядре Linux в версии 4.19,
    компанией Google был разработан WALT (Window Assisted Load Tracking) \cite{QualcommWALT},
    который предназначен специально для мобильных устройств, где важна быстрая реакция со стороны ядра
    на изменение утилизации ядерного времени, чтобы избежать деградации производительности.
    WALT использует утилизации существенно меньшего количества промежутков времени (5 вместо 32) в
    отличие от PELT и без экспоненциально движущихся средних значений, но алгоритм подсчёта утилизации
    за 1 промежуток времени совпадает с описанным выше.

    При выборе политики регулирования частот в Linux ''Schedutil'' \cite{KernelDocsSchedutil},
    WALT или PELT используются не только внутри планировщика, но и для выбора тактовой частоты ядра
    процессора, т.е. ''Schedutil'' переиспользует подсчитанное значение утилизации потока исполнения
    для регулирования частот (только в случае CFS планировщика).

    Таким образом, в Linux версии 6.1 ни стандартный планировщик, ни системы регулирования частот
    не учитывают, что производительность ядра процессора не пропорциональна тактовой частоте
    в общем случае.

\subsubsection{Альтернативные подходы к регулированию частот}

    В работе \cite{liang2013performance} предлагается использовать формулу рассчёта тактовой частоты
    ядра процессора на основе предыдущей предсказанной частоты по линейной формуле с коэффициентами,
    отвечающими за степень резкости изменения самой частоты.

    Те же авторы в статье
    \cite{chen2018learning} используют двухслойную полносвязную нейронную сеть, на вход которой
    подаются характеристики рабочей нагрузки (приложения), такие как количество исполненных инструкций,
    количество промахов в кешах инструкций/данных, в режиме реального времени в качестве
    признаков описания, а на выходе ожидается значения требуемой тактовой частоты ядра процессора.
    В качестве функции потерь для такой сети используется значения деградации производительности после
    применения значения тактовой частоты на выходе сети.

    Авторы работы \cite{haririan2020dvfs} на основе анализа существующих алгоритмов регулирования
    тактовых частот пришли к выводу, что модели, имеющие динамические параметры, являются более точными
    на практике чем модели, имеющие только статические параметры, хотя одновременно являются более
    медленными в вычислениях (т.к. необходимо регулировать динамические параметры). Дополнительно
    отмечается, что для построения модели производительности ЦП использование симуляторов является
    оптимальным для промышленного решения с точки зрения точности, скорости, сложности,
    масштабируемости и цены реализации.

    Патент \cite{johnson2012frequency} предполагает использование метрики затраченных тактов на
    инструкцию для определения тактовой частоты ядра процессора; авторы также предлагают
    группировать потоки исполнения со схожими значениями данной метрики для исполнения на
    одних ядрах процессора.

    Метрика, использующая количество промахов в кеш последнего уровня и количество тактов-ожидания
    ядра процессора (например, во время обращения в ОЗУ), используется в исследовании \cite{hebbar2022pmu}.
    Авторы используют диапазон минимально возможного и максимально возможного значений метрики,
    биективно отображая такие значения на диапазон доступных тактовых частот ядра процессора.

    Ещё одной попыткой использовать алгоритмы машинного обучения для временных потоков данных
    является подход статьи \cite{thethi2023power}, в которой применена архитектура LSTM:
    на вход сети подаётся вектор значений счётчиков микроархитектурных событий, а на выходе
    сети вектор предсказанных временных параметров потока исполнения: утилизация ядерного времени,
    количество активных потоков исполнения за фиксированный промежуток времени и количество прерываний
    ядра процессора, сгенерированных за тот же промежуток времени. Для регулирования тактовых частот
    используются только значения на выходе LSTM, в качестве функции потерь используется евклидово
    расстояние векторов. Авторы явно используют предположение линейности производительности ядра
    процессора от тактовой частоты.

    Подход, объединяющий использования DVFS как для регулирования тактовых частот ядер, так и для
    регулирования тактовых частот систем памяти, был предложен в статье \cite{deng2012coscale}.
    Подход отличается от остальных комплексным рассмотрением политики регулирования частот:
    с помощью модели энергопотребления оценивается, выгодно ли изменять частоту ОЗУ, насколько это
    повлияет на производительность ядер процессора. Тактовая частота ядер оценивается исходя из
    оценки величины затраченных тактов на инструкцию, причём используются счётчики таких
    микроархитектурных событий, как количество обращений в каждый из уровней кешей, а также
    количество тактов, затраченных на обращение в каждый из всех уровней кешей, что позволяет
    оценивать время задержки обращения в память. Однако, в большинстве устройств информация о
    количестве затраченных тактов на обращения к конкретному уровню памяти недоступна;
    как отмечают сами авторы, данная работа предназначена для регулирования частот для серверных
    систем.

\subsection{Симулятор компьютерных архитектур Gem5}

    В исследованиях в области компьютерных архитектур, их оптимизации или оценки результатов новых идей,
    связанных с параметрами таких архитектур, чаще всего используют не конечное устройство, а симуляцию
    архитектуры такого устройства, т.к. это и дешевле в разработке,
    и открывает больше возможностей в плане вариации параметров компонент архитектуры при оценке
    их влияния на разрабатываемое решение (оптимизация, алгоритм и т.д.).

    Одним из наиболее популярных и продвинутых симуляторов компьютерных систем является симулятор
    с открытым исходным кодом Gem5 \cite{binkert2011gem5}. Он поддерживает большинство современных
    архитектур: ARM, ALPHA, MIPS, Power, SPARC, AMD64 и т.д.. Для симуляции возможно использовать
    несколько типов ядер процессора \cite{gem52017ArchExpl}, среди которых ''Atomic Simple'',
    ''Timing Simple'', ''Minor'', ''O3''.

    ''Atomic Simple'' является функциональной симуляцией
    машинных инструкций, ''Timing Simple'' -- простейшей потактовой моделью исполнения машинных
    инструкций, ''Minor'' -- полноценная модель конвейера ядра процессора,
    а ''O3'' -- модель конвейера ядра процессора, поддерживающая спекулятивное исполнение (Out-of-Order).

    Gem5 поддерживает 2 режима симуляции: эмуляция системных вызовов (SE -- syscall emulation), которая
    поддерживает симуляцию одного приложения с некоторыми ограничениями (например, ввиду отсутствия таблицы
    страниц, поддерживаемой операционной системой, обращения в виртуальную память упрощено, MMU (Memory
    Management Unit) не участвует в симуляции), и полная эмуляция системы (FS -- full system).

    В данной работе используется архитектура ARM64, т.к. именно она используется в большинстве мобильных
    систем на сегодняшний день. В качестве ядра процессора выбрано ''Minor'', т.к. оно обеспечивает
    хорошую точность симуляции и на практике ядра такого типа реально используются в мобильных
    устройствах в качестве энергоэффективных. Ядро процессора ''O3'' обладает более сложным конвейером и
    поддерживает спекулятивное исполнение инструкций, такие ядра обычно используют как производительные
    (с повышенным энергопотреблением), но симуляция такого типа процессорного ядра занимает больше
    в разы больше времени, чем ''Minor'', из-за чего предпочтение было отдано ''Minor''.

    Компанией ARM Ltd. в симуляторе Gem5 было разработано процессорное ядро HPI (High Performance In-order)
    \cite{gem52017HPI} на основе ''Minor'' специально для исследовательских целей. В дальнейшем
    будет использован именно этот тип процессорного ядра.

    В качестве режима симуляции выбрана полная эмуляция системы, которая поддерживает полноценный запуск
    ядра Linux под архитектуру ARM. Именно в режиме полной эмуляции будет произведено дальнейшее
    исследование-построение модели для регулирования частот процессорных ядер.

\newpage
