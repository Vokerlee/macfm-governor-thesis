\section{Обзор существующих решений}
\label{sec:Section2} \index{Section2}

\subsection{Микроархитектура процессора}

Современный микропроцессорное ядро представляет собой многостадийный pipeline (конвейер) из
различных блоков. В зависимости от исполняемого workload'а

Наибольший интерес в данной работе представляет организация обращения
процессора в память

\subsection{Подсистема памяти в современных SoC}
\subsubsection{Архитектура подсистемы памяти}

\subsubsection{Исследования на тему bandwidth и latency}

[TODO] В работе \cite{clapp2015quantifying} рассматривается подход использования аналитической
формулы влияния bandwidth и latency памяти на производительность суперскалярного
процессора в рамках рабочих нагрузок, связанных с big data областью. В этом подходе
используется схожий принцип, предлагаемых в данной работе: использование показателя
$cpi$, который включает в себя слагаемые, связанные с циклами, потраченными на время
ожидания транзакций-обращений в память. Авторы исследуют влияние значений bandwidth
и latency на производительность, которую они выражают через $cpi$, для различных workload'ов:
latency-bound и bandwidth-bound. Однако данное исследование ограничивается
рассмотрением обращений только в DDR память при фиксированных частотах всех устройств.

[TODO] Авторы работы \cite{keramidas2010interval} предлагают 2 модели для учёта latency памяти
в рамках DVFS алгоритма. Первая модель разбивает циклы CPU на 2 компоненты: относящиеся
к ожиданию транзакций памяти и относящиеся непосредственно к вычислительным блокам CPU.
Утверждается, что при изменении частоты CPU изменяются только циклы, относящиеся к памяти,
на этом и основывается алгоритм DVFS, использующий перерасчёт времени исполнения через
циклы при различных частотах CPU. Вторая модель является модификацией-улучшением первой модели:
дополнительно предполагается, что в группе инструкций, которые обращаются в память подряд,
следует учитывать только первую инструкцию в формуле для перерасчёта циклов, которые относятся
к памяти, однако это требует наличие дополнительной информации на уровне кешей: среди всех
промахов в кеши (т.е. обращений в следующий уровень памяти) следует учитывать только первые
промахи среди группы промахов (промахов, находящихся на расстоянии порядка latency обращения
в вышележащие уровни памяти во времени).

В работе также отмечается, что следует учитывать ROB в OoO процессорах: из циклов, относящихся к
транзакциям памяти, следует вычесть ту часть циклов, которую тратит CPU на исполнение
инструкций, расположенных в логическом порядке после инструкции-обращений в память,
так как такие инструкции исполняются спекулятивно.



\subsection{Симулятор архитектуры Gem5}

\subsection{Capacity Awate Scheduling в ядре Linux}

\subsection{DVFS алгоритмы}




%%About PMU counters (from arm site)
%%About Gem5 PMU implementation

\newpage
